# NOTE: Make sure this file is consistent with .github/workflows/{unit,gpu,example}_tests.yml
.tests-default:
  variables:
    PIP_CONSTRAINT: "" # Disable pip constraint for upgrading packages
  stage: tests
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_COMMIT_TAG =~ /^\d+\.\d+\.\d+$/
    - when: manual

##### Unit Tests #####
unit:
  extends: .tests-default
  timeout: 30m
  variables:
    PYTHON: 12
    TORCH: 28
    TRANSFORMERS: latest
  image: python:3.$PYTHON
  before_script:
    # Install cmake to build onnxsim from sdists for Python 3.12 until http://github.com/daquexian/onnx-simplifier/pull/353
    - if [ "$PYTHON" = "12" ]; then apt-get update && apt-get install -y cmake; fi
    - pip install tox
  script:
    - tox -e py3$PYTHON-torch$TORCH-tf_$TRANSFORMERS-unit

##### GPU Tests #####
.gpu-tests-default:
  extends: .tests-default
  timeout: 60m
  image: nvcr.io/nvidia/pytorch:25.06-py3
  variables:
    GIT_DEPTH: 1000 # For correct version for tests/gpu/torch/quantization/plugins/test_megatron.py
  tags: [docker, linux, 2-gpu]
  before_script:
    # Add libcudnn*.so and libnv*.so to path
    - export LD_LIBRARY_PATH="/usr/lib/x86_64-linux-gnu:/usr/local/tensorrt/targets/x86_64-linux-gnu/lib:${LD_LIBRARY_PATH}"
    # Add trtexec to path
    - export PATH="/usr/local/tensorrt/targets/x86_64-linux-gnu/bin:$PATH"
    # Install git-lfs for Daring-Anteater dataset
    - apt-get update && apt-get install -y git-lfs
    - git lfs install --system

multi-gpu:
  extends: .gpu-tests-default
  script:
    # Use pre-installed packages without a new venv with tox-current-env
    - pip install tox-current-env
    - tox -e py312-cuda12-gpu --current-env

##### Example Tests #####
example:
  extends: .gpu-tests-default
  timeout: 30m
  variables:
    TEST_TYPE: pytest
  parallel:
    matrix:
      - EXAMPLE: [diffusers, llm_distill, llm_sparsity, onnx_ptq, speculative_decoding]
  script:
    - pip install ".[all,dev-test]"
    # Uninstall apex since T5 Int8 (PixArt) + Apex is not supported as per https://github.com/huggingface/transformers/issues/21391
    - if [ "$EXAMPLE" = "diffusers" ]; then pip uninstall -y apex; fi
    - find examples/$EXAMPLE -name "requirements.txt" | while read req_file; do pip install -r "$req_file" || exit 1; done
    - if [ "$TEST_TYPE" = "pytest" ]; then pytest -s tests/examples/$EXAMPLE; else bash tests/examples/test_$EXAMPLE.sh; fi

# TODO: Fix llm_qat test hang in GitLab CI
example-failing:
  extends: example
  allow_failure: true
  parallel:
    matrix:
      - EXAMPLE: [llm_qat]

example-ada:
  extends: example
  timeout: 60m
  image: nvcr.io/nvidia/tensorrt-llm/release:1.1.0rc2.post2
  tags: [docker, linux, 2-gpu, sm>=89]
  parallel:
    matrix:
      - EXAMPLE: [llm_eval, llm_ptq, vlm_ptq, llm_autodeploy]
      - EXAMPLE: [onnx_ptq]
        TEST_TYPE: bash

##### Megatron / NeMo Integration Tests #####
megatron-nemo-integration:
  extends: .tests-default
  variables:
    UPSTREAM_REF: $CI_COMMIT_REF_NAME
  trigger:
    project: omniml/integration/nmm-sandbox
    branch: main
    strategy: depend # Make sure the upstream task is waiting for the downstream task
