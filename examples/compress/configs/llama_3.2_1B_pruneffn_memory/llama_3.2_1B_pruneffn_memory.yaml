defaults:
  - /Llama-3_2-1B
  - _self_

# Input Hugging Face model to compress
input_hf_model_path: ???  # e.g., "path/to/meta-llama/Llama-3.2-1B"

# Dataset path for pruning and NAS scoring
dataset_path: ???  # e.g., "path/to/dataset"

# Working directory for compression outputs
puzzle_dir: ???  # e.g., "path/to/puzzle_dir"

# MIP memory constraint (in MiB) 
mip:
  human_constraints:
    target_memory: 2_000 # 2 GiB

# FFN intermediate sizes to search over (heterogeneous architecture)
pruning:
  intermediate_size_list: [768, 1024, 1536, 2048, 2560, 4192]  # Llama 3.2 1B baseline: 8192
